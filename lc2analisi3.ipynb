{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39bceddb",
   "metadata": {},
   "source": [
    "Basato su EVALITA 2020 HaSpeeDe (http://www.di.unito.it/~tutreeb/haspeede-evalita20/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03980a60",
   "metadata": {},
   "source": [
    "Sviluppare un classificatore basato su SVM lineari che prende in input una rappresentazione\n",
    "del testo costruita attraverso l‚Äôuso dei word embedding\n",
    "(http://www.italianlp.it/resources/italian-word-embeddings/). Riportare i seguenti risultati:\n",
    "- Testare diverse rappresentazioni del testo che variano rispetto al modo di combinare gli\n",
    "embedding delle singole parole e/o rispetto alle categorie grammaticali delle parole\n",
    "prese in considerazione. Valutare i diversi sistemi con un processo di 5-fold cross\n",
    "validation condotto sul training set;\n",
    "- Valutazione sul test set ufficiale del miglior sistema rispetto ai risultati ottenuti con il\n",
    "processo di 5-fold cross validation del punto sopra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad802e",
   "metadata": {},
   "source": [
    "I word embeddings scelti sono stati gli Italian Twitter Embeddings raccolti dal ItaliaNLP Lab (http://www.italianlp.it/download-italian-twitter-embeddings/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a00b3e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importo sqlite e specifico i path per accedere ai word embeddings e per salvarli come .txt\n",
    "import sqlite3\n",
    "\n",
    "sql_path = \"word_embeddings/twitter128.sqlite\"\n",
    "txt_path = \"word_embeddings/twitter128.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "877e0d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connessione al database sql \"twitter128\"\n",
    "con = sqlite3.connect(sql_path)\n",
    "#cursore per la connessione al database\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "780b177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrivo i dati dal database su un file di testo\n",
    "with open(txt_path, 'w+') as out_file:\n",
    "    for embedding in cur.execute(\"SELECT * FROM store\"):\n",
    "        str_embedding = [str(el) for el in embedding[:-1]]\n",
    "        out_file.write('\\t'.join(str_embedding)+'\\n')\n",
    "\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d804b8f",
   "metadata": {},
   "source": [
    "Il file di testo twitter128.txt ha una riga per parola, in cui il primo elemento √® la parola e i successivi 128 sono le componenti dell'embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d300c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "641351da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creo una funzione per caricare i word embeddings a partire dal file di testo\n",
    "def load_word_embeddings(src_path):\n",
    "    embeddings = dict()\n",
    "    #itero sulle righe del file\n",
    "    for line in open(src_path, 'r'):\n",
    "        #rimuovo spazi bianchi e separo la stringa in base ai tab, creando una lista in cui l'elemento 0 √® la parola e gli elementi da 1 in poi sono le componenti dell'embedding\n",
    "        line = line.strip().split('\\t')\n",
    "        word = line[0]\n",
    "        embedding = line[1:]\n",
    "        embedding = [float(comp) for comp in embedding] #convertiamo le componenti dell'embedding in float\n",
    "        embeddings[word] = np.asarray(embedding) #trasformiamo la lista delle componenti in un vettore di numpy\n",
    "    return embeddings\n",
    "#embeddings √® un dizionario che ha la parola come chiave e le componenti dell'embedding per quella parola in un array numpy come valore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27515038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00588687e-02,  9.70248729e-02,  2.28946786e-02, -1.01958990e-01,\n",
       "        1.01152070e-01, -3.84831540e-02, -1.31021678e-01,  6.18477315e-02,\n",
       "       -2.02476829e-02,  5.94022200e-02, -1.06382497e-01,  9.90854874e-02,\n",
       "       -4.53294665e-02, -8.76475945e-02,  2.27265339e-02, -3.18616405e-02,\n",
       "       -1.52194872e-01,  6.49362504e-02,  9.82077718e-02, -1.14106350e-01,\n",
       "        1.01975193e-02, -1.52585441e-02,  1.42587781e-01,  5.78809668e-05,\n",
       "        7.77927646e-03,  1.13248117e-01, -2.31339168e-02, -7.06618577e-02,\n",
       "        1.82080530e-02,  6.44217804e-02, -1.78829823e-02, -3.65133770e-02,\n",
       "        1.48065194e-01, -1.08065717e-01,  7.60474950e-02,  1.62513033e-01,\n",
       "        1.47792243e-03, -8.97888169e-02,  1.41946062e-01, -3.19051333e-02,\n",
       "        2.27965806e-02, -3.13461348e-02,  5.34125715e-02,  3.67401130e-02,\n",
       "       -1.44961536e-01, -7.24047348e-02, -2.31131930e-02, -3.72798480e-02,\n",
       "       -8.22194964e-02,  3.99212092e-02,  1.12063788e-01,  1.43978551e-01,\n",
       "        9.28448662e-02,  1.50347114e-01, -4.28403988e-02, -1.40133753e-01,\n",
       "       -1.16505455e-02, -1.54733360e-01, -4.58833948e-02, -2.04225238e-02,\n",
       "       -1.32174611e-01,  5.76049015e-02, -2.40103509e-02, -2.61766352e-02,\n",
       "        7.44352788e-02,  1.23691790e-01, -1.17183611e-01, -1.84472706e-02,\n",
       "       -4.95623127e-02, -2.08616446e-04,  3.99940796e-02, -4.60291207e-02,\n",
       "       -1.73958633e-02,  5.81168607e-02, -6.57419041e-02, -5.37965894e-02,\n",
       "       -6.34635985e-03,  1.34171501e-01,  1.15792647e-01,  1.30167045e-02,\n",
       "        1.13228768e-01, -1.70476988e-01,  1.21958382e-01,  1.22831099e-01,\n",
       "        1.53195217e-01, -1.35508282e-02, -3.49325798e-02,  2.11795024e-03,\n",
       "        4.24168445e-02,  1.75603688e-01,  1.88596845e-01,  6.36779368e-02,\n",
       "       -9.32761580e-02, -7.20165968e-02,  1.55852899e-01,  1.18984759e-01,\n",
       "       -5.24427742e-02,  1.45707384e-03, -3.06436885e-03, -1.53005779e-01,\n",
       "        5.18133864e-02,  2.02952363e-02,  6.42909035e-02,  7.78029263e-02,\n",
       "       -2.65270052e-03, -8.75175297e-02,  1.30860403e-01,  1.65433571e-01,\n",
       "       -2.86173653e-02, -5.21183908e-02,  5.12274913e-02, -6.18858598e-02,\n",
       "        4.93928120e-02, -9.17523429e-02,  3.61349583e-02,  1.33369669e-01,\n",
       "        9.86780226e-02,  6.84009865e-02, -4.04176340e-02, -1.08364858e-01,\n",
       "        1.59872726e-01, -5.20326123e-02,  8.58047307e-02,  6.76299855e-02,\n",
       "        1.83445752e-01,  7.13148639e-02,  1.40315737e-03,  1.20762456e-02])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#carico gli embeddings\n",
    "embeddings = load_word_embeddings(txt_path)\n",
    "#stampo gli embeddings della parola \"ciao\" per vedere se tutto √® avvenuto correttamente\n",
    "embeddings[\"ciao\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf4ad5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#carico il mio dataset dalla cartella con i file .conllu utilizzata anche per la scorsa task\n",
    "conllu_dir = 'profiling_output/11925'\n",
    "#inizializzo una lista che andr√≤ a riempire coi percorsi dei file .conllu\n",
    "all_documents_paths = []\n",
    "#ottengo, scorrendo la directory, una lista completa dei percorsi per accedere ai vari file\n",
    "for file_name in os.listdir(conllu_dir):\n",
    "    file_path = os.path.join(conllu_dir, file_name)\n",
    "    all_documents_paths.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e65dc21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#funzione per la normalizzazione di numeri. la scrivo per richiamarla dentro normalize_text\n",
    "def get_digits(text):\n",
    "    try:\n",
    "        #prova a convertire il testo in intero e lo salva eventualmente in una variabile val\n",
    "        val = int(text)\n",
    "    except:\n",
    "        #se la conversione fallisce, sostituisce tutte le cifre nel testo con la stringa @Dg (\\d corrisponde a una singola cifra)\n",
    "        text = re.sub('\\d', '@Dg', text)\n",
    "        return text\n",
    "    #se il valore √® compreso tra 0 e 9999, lo restituisce come stringa. altrimenti, restituisce una stringa del tipo DIGLEN_Lunghezza, in base alla lunghezza della stringa calcolata con len\n",
    "    if val >= 0 and val < 9999:\n",
    "        return str(val)\n",
    "    else:\n",
    "        return \"DIGLEN_\" + str(len(str(val)))\n",
    "\n",
    "#funzione per la normalizzazione del testo\n",
    "def normalize_text(word):\n",
    "    #controlla se la stringa √® un url, se √® presente al suo interno http oppure sia . che /. se lo √®, la sostituisce con \"___URL___\" e la ritorna.\n",
    "    if \"http\" in word or (\".\" in word and \"/\" in word):\n",
    "        word = str(\"___URL___\")\n",
    "        return word\n",
    "    #controlla se la stringa ha pi√π di 26 caratteri. se s√¨, la sostituisce con \"__LONG-LONG__\" e la ritorna.\n",
    "    if len(word) > 26:\n",
    "        return \"__LONG-LONG__\"\n",
    "    #richiama get_digits e memorizzo il risultato nella variabile new_word\n",
    "    new_word = get_digits(word)\n",
    "    #controlla se new_word √® diversa da word e quindi se get_digits l'ha cambiata. se s√¨, aggiorno word (get_digits la cambia se la parola contiene sia cifre numeriche che altri caratteri, o se √® un numero superiore a 9999).\n",
    "    if new_word != word:\n",
    "        word = new_word\n",
    "    #se la prima lettera √® maiuscola, capitalizza la parola (prima maiuscola, il resto minuscole)\n",
    "    if word[0].isupper():\n",
    "        word = word.capitalize()\n",
    "    #se la prima lettera non √® maiuscola (quindi √® minuscola), rende tutta la parola in lettere minuscole\n",
    "    else:\n",
    "        word = word.lower()\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1f9bf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_from_file(src_path):\n",
    "    #inizializzo la lista dei token, per ora vuota\n",
    "    document_tokens = []\n",
    "    #lines_to_skip serve per tenere traccia delle righe da saltare\n",
    "    lines_to_skip = 0\n",
    "    #take_pos serve per tenere traccia se prendere o meno la POS della prossima parola\n",
    "    take_pos = False\n",
    "    #itero sulle righe del file\n",
    "    for line in open(src_path, 'r'):\n",
    "        #controllo se il primo carattere √® una cifra (dovrebbe esserlo)\n",
    "        if line[0].isdigit():\n",
    "            #rimuove gli spazi bianchi all'inizio e alla fine della riga e la trasforma in una lista, con gli elementi separati da tab\n",
    "            splitted_line = line.strip().split('\\t')\n",
    "            if '-' in splitted_line[0]:\n",
    "                #se ho trovato un -, trasformo il primo elemento della lista a sua volta in una lista, separata da -\n",
    "                skip_ids = splitted_line[0].split('-')\n",
    "                #aggiorno lines_to_skip per sapere quante righe saltare\n",
    "                lines_to_skip = int(skip_ids[1]) - int(skip_ids[0]) + 1 #l'indice ci indica quali righe saltare\n",
    "                take_pos = True #booleano che indica che dobbiamo prendere la pos della prossima parola\n",
    "                #normalizzo la parola riprendendo la funzione normalize_text\n",
    "                word = normalize_text(splitted_line[1])\n",
    "                #estraggo la pos della parola\n",
    "                pos = splitted_line[3]\n",
    "                #creo il token come dizionario, alla chiave \"word\" metto la parola, alla chiave \"pos\" metto un placeholder\n",
    "                token = {\n",
    "                    'word': word,\n",
    "                    'pos': '_'\n",
    "                }\n",
    "                #aggiungo il token alla lista dei token\n",
    "                document_tokens.append(token)\n",
    "            else: #quindi no trattino nel primo elemento\n",
    "                if lines_to_skip == 0: #se non ci sono righe da saltare\n",
    "                    #normalizzo la parola riprendendo la funzione normalize_text\n",
    "                    word = normalize_text(splitted_line[1])\n",
    "                    #estraggo la pos della parola\n",
    "                    pos = splitted_line[3]\n",
    "                    #creo il token come dizionario, alla chiave \"word\" metto la parola, alla chiave \"pos\" metto il pos\n",
    "                    token = {\n",
    "                        'word': word,\n",
    "                        'pos': pos\n",
    "                    }\n",
    "                    #aggiungo il token alla lista dei token\n",
    "                    document_tokens.append(token)\n",
    "                if take_pos:\n",
    "                    pos = splitted_line[3]\n",
    "                    #aggiorno il pos del token precedente\n",
    "                    document_tokens[-1]['pos'] = pos\n",
    "                    #reimposto take_pos come falso\n",
    "                    take_pos = False\n",
    "                #decrementa di 1 lines_to_skip, ma, se diventa negativo, lo riporta a 0\n",
    "                lines_to_skip = max(0, lines_to_skip-1)\n",
    "    return document_tokens\n",
    "\n",
    "#devo fare cos√¨ per evitare di avere confusione nel caso di parole composte, che non hanno POS e i cui numeri hanno un trattino, perch√© sono seguite dalle singole componenti; per fare un esempio:\n",
    "# 5-6\tfarla\t_\t_\t_\t_\t_\t_\t_\t_\n",
    "# 5\tfar\tfare\tVERB\tV\tVerbForm=Inf\t2\tadvcl\t_\t_\n",
    "# 6\tla\tlo\tPRON\tPC\tClitic=Yes|Gender=Fem|Number=Sing|Person=3|PronType=Prs\t5\tobj\t_\t_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fcc053f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': '.', 'pos': 'PUNCT'},\n",
       " {'word': '#pianominniti', 'pos': 'PROPN'},\n",
       " {'word': 'prevede', 'pos': 'VERB'},\n",
       " {'word': 'regalia', 'pos': 'NOUN'},\n",
       " {'word': 'di', 'pos': 'ADP'},\n",
       " {'word': '@dg@dg@dg@dg‚Ç¨', 'pos': 'PROPN'},\n",
       " {'word': 'a', 'pos': 'ADP'},\n",
       " {'word': '#immigrati', 'pos': 'NOUN'},\n",
       " {'word': 'X', 'pos': 'PROPN'},\n",
       " {'word': 'rimpatrio', 'pos': 'NOUN'},\n",
       " {'word': 'volontario+@dg@dg@dg‚Ç¨', 'pos': 'PROPN'},\n",
       " {'word': 'X', 'pos': 'ADJ'},\n",
       " {'word': 'rifarsi', 'pos': 'VERB'},\n",
       " {'word': '1', 'pos': 'NUM'},\n",
       " {'word': 'vita', 'pos': 'NOUN'},\n",
       " {'word': 'in', 'pos': 'ADP'},\n",
       " {'word': 'patria.viaggio', 'pos': 'NOUN'},\n",
       " {'word': 'sempre', 'pos': 'ADV'},\n",
       " {'word': 'a', 'pos': 'ADP'},\n",
       " {'word': 'spese', 'pos': 'NOUN'},\n",
       " {'word': 'nostre', 'pos': 'DET'},\n",
       " {'word': '.', 'pos': 'PUNCT'},\n",
       " {'word': 'üò°', 'pos': 'SYM'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lista che conterr√† i tokens di ogni documento, per ora vuota\n",
    "all_documents = []\n",
    "\n",
    "#estraggo tutti i tokens da ogni documento di all_documents_path e li appendo nella lista all_documents\n",
    "for document_path in all_documents_paths:\n",
    "    document_tokens = get_tokens_from_file(document_path)\n",
    "    all_documents.append(document_tokens)\n",
    "    \n",
    "#stampo tutti i tokens del documento alla posizione 111 per verificare che tutto sia stato eseguito correttamente\n",
    "all_documents[111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c4aff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcola la media degli embeddings di un documento\n",
    "def compute_embeddings_mean(document_embeddings):\n",
    "    #sum_array √® la somma degli embeddings\n",
    "    sum_array = np.sum(document_embeddings, axis=0)\n",
    "    #la media √® la somma degli embeddings divisa per il numero di embeddings\n",
    "    mean_array = np.divide(sum_array, len(document_embeddings))\n",
    "    return mean_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd40c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1¬∞ metodo di calcolo media: calcola la media di tutti i word embeddings\n",
    "\n",
    "def compute_all_embeddings_mean(document_tokens):\n",
    "    #inizializzo una lista che conterr√† gli embeddings dei tokens del documento\n",
    "    document_embeddings = []\n",
    "    \n",
    "    #itero sui tokens\n",
    "    for token in document_tokens:\n",
    "        #estraggo la parola dal dizionario token\n",
    "        word = token['word']\n",
    "        #controllo se la parola √® presente nei miei embeddings\n",
    "        if word in embeddings:\n",
    "            #se la parola √® presente nei miei embeddings, la appendo alla lista document_embeddings\n",
    "            document_embeddings.append(embeddings[word])\n",
    "    \n",
    "    #controllo se document_embeddings √® vuoto (quindi nessuna parola del documento ha un embeddings associato nei miei embeddings)\n",
    "    if len(document_embeddings) == 0:\n",
    "        #se document_embeddings √® vuoto, creo un array numpy di 0 (di dimensione 128)\n",
    "        mean_document_embeddings = np.zeros(128)\n",
    "    else:\n",
    "        #se document_embeddings non √® vuoto, chiamo la funzione compute_document_mean per calcolare la media degli embeddings\n",
    "        mean_document_embeddings = compute_embeddings_mean(document_embeddings)\n",
    "    return mean_document_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a6cc960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2¬∞ metodo di calcolo media: calcola la media degli embeddings solo di aggettivi, nomi e verbi\n",
    "\n",
    "def compute_filtered_embeddings_mean(document_tokens):\n",
    "    #inizializzo una lista che conterr√† gli embeddings dei tokens del documento\n",
    "    document_embeddings = []\n",
    "    \n",
    "    #itero sui tokens\n",
    "    for token in document_tokens:\n",
    "        #estraggo sia la parola che la POS dal dizionario token\n",
    "        word = token['word']\n",
    "        pos = token['pos']\n",
    "        #controllo se la parola √® presente nei miei embeddings e se il POS √® uno tra aggettivo, nome o verbo\n",
    "        if word in embeddings and pos in ['ADJ', 'NOUN', 'VERB']:\n",
    "            #se le condizioni sopra sono vere, aggiungo la parola alla lista document_embeddings\n",
    "            document_embeddings.append(embeddings[word])\n",
    "    \n",
    "    #controllo se document_embeddings √® vuoto (quindi nessuna parola del documento ha un embeddings associato nei miei embeddings)\n",
    "    if len(document_embeddings) == 0:\n",
    "        #se document_embeddings √® vuoto, creo un array numpy di 0 (di dimensione 128)\n",
    "        mean_document_embeddings = np.zeros(128)\n",
    "    else:\n",
    "        #se document_embeddings non √® vuoto, chiamo la funzione compute_document_mean per calcolare la media degli embeddings\n",
    "        mean_document_embeddings = compute_embeddings_mean(document_embeddings)\n",
    "    return mean_document_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb865a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3¬∞ metodo di calcolo media: calcola la media degli embeddings di aggettivi, nomi e verbi separatamente, e concatena i 3 vettori ottenuti\n",
    "\n",
    "def compute_filtered_embeddings_sep_means(document_tokens):\n",
    "    #inizializzo tre diverse liste per contenere embeddings, una per aggettivi, una per nomi, e una per verbi\n",
    "    adj_embeddings = []\n",
    "    noun_embeddings = []\n",
    "    verb_embeddings = []\n",
    "    \n",
    "    #itero sui tokens\n",
    "    for token in document_tokens:\n",
    "        #estraggo sia la parola che la POS dal dizionario token\n",
    "        word = token['word']\n",
    "        pos = token['pos']\n",
    "        #controllo se la parola √® presente nei miei embeddings e se il POS √® aggettivo\n",
    "        if word in embeddings and pos in ['ADJ']:\n",
    "            #se le condizioni sopra sono vere, aggiungo la parola alla lista adj_embeddings\n",
    "            adj_embeddings.append(embeddings[word])\n",
    "        #controllo se la parola √® presente nei miei embeddings e se il POS √® nome\n",
    "        elif word in embeddings and pos in ['NOUN']:\n",
    "            #se le condizioni sopra sono vere, aggiungo la parola alla lista noun_embeddings\n",
    "            noun_embeddings.append(embeddings[word])\n",
    "        #controllo se la parola √® presente nei miei embeddings e se il POS √® verbo\n",
    "        elif word in embeddings and pos in ['VERB']:\n",
    "            #se le condizioni sopra sono vere, aggiungo la parola alla lista verb_embeddings\n",
    "            verb_embeddings.append(embeddings[word])\n",
    "    \n",
    "    #per ognuna delle tre liste contenenti embeddings, controllo se sono vuote; se s√¨, creo un array numpy di 0 (di dimensione 128), altrimenti chiamo la funzioen compute_document_mean per calcolare la media degli embeddings\n",
    "    if len(adj_embeddings) == 0:\n",
    "        mean_adj_embeddings = np.zeros(128)\n",
    "    else:\n",
    "        mean_adj_embeddings = compute_embeddings_mean(adj_embeddings)\n",
    "        \n",
    "    if len(noun_embeddings) == 0:\n",
    "        mean_noun_embeddings = np.zeros(128)\n",
    "    else:\n",
    "        mean_noun_embeddings = compute_embeddings_mean(noun_embeddings)\n",
    "        \n",
    "    if len(verb_embeddings) == 0:\n",
    "        mean_verb_embeddings = np.zeros(128)\n",
    "    else:\n",
    "        mean_verb_embeddings = compute_embeddings_mean(verb_embeddings)  \n",
    "    \n",
    "    #eseguo la concatenazione degli embeddings medi di aggettivi, nomi e verbi. saranno quindi presenti 128x3=384 valori.\n",
    "    mean_document_embeddings = np.concatenate([mean_adj_embeddings, mean_noun_embeddings, mean_verb_embeddings], axis=None)\n",
    "    return mean_document_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "004b36ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero e media di tutti gli embeddings:\n",
      "128\n",
      "[-0.02775776  0.03938989 -0.00629901 -0.09540768 -0.02298989 -0.04438516\n",
      " -0.02631047 -0.02981493  0.06303736 -0.06666578 -0.02740279  0.05675423\n",
      "  0.01849988 -0.07019756  0.00514951 -0.00465845  0.04153982 -0.0056832\n",
      " -0.00995647  0.0284641  -0.04878962 -0.05391109 -0.02918607  0.010651\n",
      "  0.08411159 -0.00133598 -0.04336065 -0.02887877 -0.04764055 -0.02627937\n",
      "  0.06848478  0.08748336  0.00389155 -0.0065819   0.06068013  0.01936245\n",
      "  0.02808932 -0.01449003 -0.01192433 -0.06747614  0.04377068  0.0305988\n",
      " -0.09687228 -0.00313677 -0.05054593 -0.01249226 -0.00455744 -0.0032782\n",
      "  0.09162627 -0.05142696  0.02338257  0.09695108  0.0091481   0.01609148\n",
      "  0.05263629  0.06450496  0.05652132  0.04860144  0.01394459 -0.009985\n",
      " -0.03681103 -0.0579086   0.08197123  0.06187929  0.00200779 -0.07084321\n",
      " -0.0002449  -0.01253242 -0.01165658 -0.01927183  0.00799208  0.0491647\n",
      " -0.00693922 -0.02615696  0.03332344  0.06120816  0.01451376 -0.03288106\n",
      " -0.05986465 -0.01009319 -0.00308902  0.03167837 -0.01700839 -0.04194171\n",
      " -0.11468933 -0.06333478 -0.06294118  0.00257462  0.02920991 -0.02469935\n",
      "  0.04722143 -0.05667999  0.01848755 -0.02627277 -0.09187773  0.0198833\n",
      " -0.05715729  0.05084912 -0.0023967  -0.06897134 -0.00034186 -0.04090854\n",
      "  0.04254605 -0.0047376   0.06876636  0.04090956  0.02346386  0.00514778\n",
      " -0.04954187 -0.02632972 -0.08363396  0.010297    0.00224754 -0.03766857\n",
      "  0.00154632  0.00194863  0.01171724 -0.02198376 -0.04713325 -0.02965079\n",
      "  0.00836394 -0.02575637 -0.00592706  0.04651982  0.03744893  0.01869044\n",
      " -0.03568308  0.04443001]\n",
      "\n",
      "Numero e media embeddings parole piene:\n",
      "128\n",
      "[-0.07230329 -0.02480801 -0.01037635 -0.07722872  0.01128125 -0.01100872\n",
      " -0.0019586  -0.01604739  0.02274009 -0.04659087 -0.07320359  0.02504018\n",
      "  0.06719949 -0.05240347 -0.0459852  -0.01310915  0.09740323  0.03220139\n",
      " -0.0672824   0.02209202 -0.0335763  -0.01074237 -0.09058384  0.02046814\n",
      "  0.07552678  0.00193578 -0.01196731 -0.03095389 -0.02438346 -0.02285657\n",
      "  0.01186942  0.11365504 -0.02727886  0.00239319  0.0475386   0.00793811\n",
      "  0.03213522  0.01250913 -0.00636729 -0.05664935  0.04813948  0.00616902\n",
      " -0.03793326 -0.01807491 -0.08961437 -0.00414097 -0.02190732 -0.02099015\n",
      "  0.08482733 -0.06644978  0.06410953  0.02492701  0.03972723  0.05103651\n",
      "  0.0391471   0.08226967  0.00312051  0.03015468  0.04365008 -0.02304744\n",
      "  0.0461208  -0.02592091  0.03533183  0.01184065 -0.03176793 -0.15107013\n",
      " -0.04054394 -0.04299784 -0.01096182  0.03472872  0.03006252  0.03303532\n",
      " -0.01955597 -0.0179766   0.04513516  0.07803958 -0.01432313 -0.02458611\n",
      " -0.07051326 -0.00068327 -0.00664829  0.03064121 -0.06702428 -0.04988291\n",
      " -0.10176283 -0.0609316  -0.10579084  0.00535796  0.02151574 -0.02810464\n",
      "  0.10476485 -0.04315393  0.00024414 -0.02906652 -0.03549874  0.02854949\n",
      " -0.05728659  0.01159413 -0.02074121 -0.10468877  0.02756334 -0.08786409\n",
      "  0.07015615 -0.01678899  0.07615216 -0.01438326 -0.04141744  0.08026613\n",
      " -0.05809012  0.0036377  -0.0319949   0.03230761 -0.00096061  0.01926456\n",
      " -0.06280888 -0.0110947  -0.06363881 -0.02445723  0.0217425  -0.01835811\n",
      "  0.02832471 -0.00948405  0.06591959  0.07685147  0.03354816 -0.0079589\n",
      " -0.09713554  0.07576699]\n",
      "\n",
      "Numero e media separate embeddings parole piene:\n",
      "384\n",
      "[-1.48439869e-01 -2.45576575e-02  5.73432911e-02 -2.11671623e-02\n",
      " -2.21596630e-02 -9.87036973e-02 -7.04942364e-02 -8.45908541e-02\n",
      "  1.33311171e-02  7.48153124e-03 -5.04981168e-02 -4.78744507e-04\n",
      "  4.33270317e-02 -1.07923098e-01 -7.97646213e-03 -3.88955325e-03\n",
      "  1.77062344e-01  8.43758006e-02 -9.85060511e-02 -3.35036968e-02\n",
      " -4.77571827e-02 -3.89394164e-03 -5.78714237e-02  1.78716555e-02\n",
      "  7.99754299e-02  9.27616246e-02  3.38220038e-02  2.12207027e-02\n",
      " -7.61599448e-02  6.46323222e-03  2.16151392e-02  1.02198662e-01\n",
      "  2.61584120e-02  3.38969734e-02  1.32794101e-02  4.00696322e-02\n",
      " -2.97965100e-02  1.27214864e-02 -3.74287199e-02 -3.11485804e-02\n",
      "  2.44876277e-03  8.33037701e-02 -9.44504123e-02 -1.58725239e-02\n",
      " -4.94540539e-02  4.56367135e-02 -3.11395191e-02 -8.33940133e-03\n",
      "  1.38362374e-01 -5.64666893e-02  1.01696901e-01  1.71920210e-02\n",
      "  6.18693596e-02  6.21170625e-02 -3.66659416e-02  1.08300321e-01\n",
      "  5.76263871e-02  1.14104692e-02  3.38574406e-02  4.87985704e-02\n",
      " -2.63686171e-02 -4.90743015e-02  7.68781600e-02  1.02486685e-02\n",
      "  2.48820763e-02 -1.92914762e-01 -3.80895864e-02 -6.87173083e-02\n",
      "  6.02352992e-02 -4.80732508e-03  5.10577802e-02  5.39715365e-02\n",
      " -5.15117180e-02 -8.37446116e-02  1.05801661e-01  1.51738536e-01\n",
      " -4.06354638e-02 -3.12023144e-03 -8.31114193e-02 -3.80294658e-02\n",
      "  4.68839705e-03  2.65027508e-02 -1.02739718e-01 -3.16218957e-02\n",
      " -1.58495527e-01 -1.18547413e-01 -1.63101476e-01 -7.64655294e-02\n",
      "  4.64159334e-02 -2.90981065e-02  1.97234765e-01 -3.45217288e-02\n",
      " -7.46420864e-03  2.74060229e-02 -5.30480412e-02  4.44133747e-02\n",
      "  5.44477757e-02  7.32160348e-03 -6.77998839e-02 -6.62287027e-02\n",
      " -8.81334785e-02 -1.31354317e-01 -8.40637647e-03 -7.11091422e-03\n",
      "  1.00139432e-01  4.36652823e-02 -1.62043236e-03  4.33025295e-02\n",
      " -6.53143451e-02  4.81652692e-02  6.31217211e-02  7.77951032e-02\n",
      "  7.36238612e-02 -6.54611737e-02 -8.64435621e-02 -4.95939180e-02\n",
      " -1.19843844e-01 -8.43206588e-02  5.02633164e-02  1.90096498e-02\n",
      " -1.70267969e-02 -4.76898663e-02  5.38292043e-02  1.17240239e-01\n",
      "  9.56998989e-02 -6.19478002e-02 -3.53385573e-02  1.10332165e-01\n",
      " -8.84810562e-02 -4.31822191e-02  5.47548135e-04 -8.74064403e-02\n",
      " -1.33489408e-02  4.50764702e-02  3.81316347e-02 -7.61841051e-03\n",
      "  4.31777239e-02 -4.44084182e-02 -9.22328749e-02  3.73063590e-02\n",
      "  9.40629890e-02 -3.77286230e-02 -4.83086137e-02 -4.44912749e-02\n",
      "  3.46758862e-02  1.62864427e-02 -4.89959667e-02  7.46036818e-02\n",
      " -1.89663482e-02  2.75621836e-02 -9.42359182e-02  2.62292723e-02\n",
      "  7.03046142e-02 -8.38070561e-02 -2.02484376e-02 -4.23699295e-02\n",
      " -1.07385083e-02 -5.12715851e-02 -1.07460031e-02  9.65274821e-02\n",
      " -9.45389972e-02 -1.48436078e-02  4.77824483e-02 -6.43870234e-02\n",
      "  4.32344576e-02 -1.46068732e-02  2.33547760e-02 -1.07486919e-01\n",
      "  5.36926053e-02 -4.14908938e-02 -1.49034224e-02 -6.12639091e-03\n",
      " -1.39231811e-01 -5.28551427e-02 -6.13902165e-02 -5.30605108e-02\n",
      "  3.72610241e-02 -5.29606864e-02  3.49183393e-02  2.87393807e-02\n",
      "  9.82565247e-03  3.61709963e-02  8.07622212e-02  6.93260984e-02\n",
      "  3.38638804e-02  6.93196213e-02  4.21320728e-02 -3.24580011e-02\n",
      "  9.62776790e-02 -2.62704218e-02 -7.92518941e-03  8.77358299e-03\n",
      " -4.62581565e-02 -1.82182149e-01 -5.87582135e-02 -2.22232143e-02\n",
      " -4.18916338e-02  8.15200135e-02  1.60598295e-02  6.73303766e-02\n",
      " -1.53186638e-02  3.27410263e-02  2.12502694e-02  3.30574429e-02\n",
      "  1.68295858e-02  1.75535927e-02 -4.03146235e-02  2.73848331e-02\n",
      " -1.64086657e-02  4.33956025e-02 -7.04606337e-02 -7.36595429e-02\n",
      " -3.68898200e-02 -3.75895894e-02 -1.30146506e-01  5.64211169e-02\n",
      " -2.64661275e-02 -4.57670242e-02  3.96624158e-02 -3.20634014e-02\n",
      "  8.52876032e-04 -3.74136890e-02 -3.14518233e-02  2.76367615e-02\n",
      " -1.29177404e-01  5.62135105e-02 -4.85637331e-02 -1.26330121e-01\n",
      "  9.53167331e-02 -9.80190852e-02  1.18911083e-01  6.71752977e-03\n",
      "  5.46113141e-02 -7.06022071e-02 -4.72859937e-02  1.05452812e-01\n",
      " -6.14962103e-02 -5.12635000e-02 -8.29393876e-02  3.18078722e-02\n",
      " -6.02710433e-02  3.44451284e-02 -9.15058215e-02  2.39102046e-02\n",
      " -5.19676550e-02  2.78585749e-02 -1.19250553e-02 -5.87080618e-02\n",
      "  1.53232086e-02 -1.73352808e-02  8.56830242e-02  7.80412816e-02\n",
      "  2.64237567e-02 -2.98701910e-03 -8.17607517e-02  5.40753094e-02\n",
      "  1.28503174e-01  2.98139229e-02 -1.78587332e-01 -1.58818662e-01\n",
      "  1.52053669e-01 -3.87435290e-03  1.48419729e-02  9.57525820e-02\n",
      " -1.97548848e-02 -1.61283001e-01 -6.15266673e-02  3.92794833e-02\n",
      "  3.43539119e-02  1.46112368e-02 -1.15032420e-01  6.25980198e-02\n",
      "  1.26267061e-01 -2.44025830e-02 -5.96943796e-02 -2.42515132e-02\n",
      " -4.90443967e-02 -1.39352888e-01 -1.45052448e-01  8.37774202e-03\n",
      "  8.22959691e-02  7.75126070e-02 -7.87025541e-02 -1.01054944e-01\n",
      "  3.82346511e-02  3.74887674e-03  6.02242500e-02  1.87950492e-01\n",
      "  6.76269978e-02 -8.90395977e-03  1.15325429e-01  1.60650477e-01\n",
      "  1.22700989e-01  9.34324414e-02 -3.34106535e-02  4.48618419e-02\n",
      "  1.22861512e-01 -5.12072258e-03  6.01154659e-03 -5.83252609e-02\n",
      " -2.10827049e-02  4.24462110e-02  1.15005791e-01  4.99194413e-02\n",
      "  1.20456174e-01 -1.26883224e-01  7.65083730e-02  2.89598964e-02\n",
      "  8.51476863e-02  7.34719411e-02  6.59278259e-02  6.90390915e-02\n",
      " -1.98121354e-01 -4.98517044e-02  6.77894056e-02 -1.38507783e-01\n",
      "  4.06289920e-02  2.14344226e-02  8.20102021e-02  2.42257938e-02\n",
      " -1.01597242e-01  2.59551890e-02  9.19014588e-03 -5.38827889e-02\n",
      " -6.05665967e-02 -2.65730470e-02  3.00800856e-02 -1.11722276e-01\n",
      "  3.16435918e-02 -3.85934450e-02 -4.54314006e-03  6.55880794e-02\n",
      " -5.51566221e-02 -1.93936989e-01 -1.35912865e-01 -1.01951873e-02\n",
      " -4.05528117e-05  6.54965988e-04  1.47156538e-02 -1.50750661e-02\n",
      " -1.82916448e-01 -1.57260168e-02  8.18974078e-02  1.58154853e-02\n",
      "  1.15660943e-01  2.68694703e-02  1.15132309e-01 -9.36899111e-02\n",
      "  1.38346562e-02 -1.16970092e-01 -1.25409132e-02 -4.40078293e-04\n",
      " -6.50828555e-02 -1.13718964e-01  1.56843737e-01 -1.16684847e-01\n",
      "  5.56968115e-02  2.95813680e-02  8.10164139e-02 -1.06664695e-01\n",
      "  9.28001702e-02  3.81764844e-02 -1.03405803e-01  7.86333084e-02\n",
      " -3.34234089e-02  7.92861432e-02 -6.93946853e-02 -5.71681820e-02\n",
      "  2.78017446e-02  1.43174350e-01  7.05513135e-02 -3.91109809e-02\n",
      "  1.37577774e-02 -6.16777577e-02  6.57035559e-02  2.79562455e-02\n",
      "  1.58032209e-01  9.04812962e-02  3.08100693e-02 -7.49551971e-03\n",
      " -6.93821236e-02  8.51032361e-02 -2.66853869e-01  7.17116818e-02]\n"
     ]
    }
   ],
   "source": [
    "#stampo delle prove calcolando la media degli embeddings dei token del primo documento nelle varie modalit√† per vedere che tutto abbia funzionato correttamente\n",
    "doc_0_tokens = all_documents[0]\n",
    "print('Numero e media di tutti gli embeddings:')\n",
    "print(len(compute_all_embeddings_mean(doc_0_tokens)))\n",
    "print(compute_all_embeddings_mean(doc_0_tokens))\n",
    "print('\\nNumero e media embeddings parole piene:')\n",
    "print(len(compute_filtered_embeddings_mean(doc_0_tokens)))\n",
    "print(compute_filtered_embeddings_mean(doc_0_tokens))\n",
    "print('\\nNumero e media separate embeddings parole piene:')\n",
    "print(len(compute_filtered_embeddings_sep_means(doc_0_tokens)))\n",
    "print(compute_filtered_embeddings_sep_means(doc_0_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a58f6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione per estrarre features dai documenti. utilizza una delle 3 funzioni precedenti per ottenere la media degli embedding a seconda del parametro method, che pu√≤ essere \"all\", \"filtered\" o \"filtered_sep\"\n",
    "def extract_features(documents, method):\n",
    "    dataset_features = []\n",
    "    for document_tokens in documents:\n",
    "        if method == \"all\":\n",
    "            document_embeddings = compute_all_embeddings_mean(document_tokens)\n",
    "        elif method == \"filtered\":\n",
    "            document_embeddings = compute_filtered_embeddings_mean(document_tokens)\n",
    "        elif method == \"filtered_sep\":\n",
    "            document_embeddings = compute_filtered_embeddings_sep_means(document_tokens)\n",
    "        else:\n",
    "            raise Exception(f'Invalid element {method}')\n",
    "        dataset_features.append(document_embeddings)\n",
    "    return dataset_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "486a2977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6837, 128)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tentativo 1, calcola la media di tutti i word embeddings.\n",
    "all_features = extract_features(all_documents, \"all\")\n",
    "\n",
    "#stampo il numero dei documenti e il numero di features all'interno di uno per verificare che tutto sia andato correttamente\n",
    "len(all_features), len(all_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf34b7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creo una lista di etichette in base ai nomi dei documenti\n",
    "def create_label_list(all_documents_paths):\n",
    "    labels = []\n",
    "    for document_path in all_documents_paths:\n",
    "        document_path = document_path[:-len('.conllu')]\n",
    "        #divido ogni file path, senza .conllu, in base al #, trasformandolo in una lista che ha l'id a posizione 0 e hs a posizione 1\n",
    "        splitted_file_path = document_path.split('#')\n",
    "        #salvo hs nella variabile hs\n",
    "        hs = splitted_file_path[1]\n",
    "        #appendo il valore di hs nella lista delle labels\n",
    "        labels.append(hs)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca495294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '0', '0', '1', '1', '0', '0', '1', '0', '1', '0', '1', '0', '0', '1']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creo la lista delle labels e ne stampo 15 per vedere se tutto √® andato a buon fine\n",
    "all_labels = create_label_list(all_documents_paths)\n",
    "all_labels[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3c73482",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6837, 128)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalizzo le features di train attraverso il MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(all_features)\n",
    "\n",
    "#stampo le dimensioni dell'array X_train per verificare che tutto sia andato correttamente\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1631a4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5469 1368\n",
      "5469 1368\n",
      "5470 1367\n",
      "5470 1367\n",
      "5470 1367\n",
      "Accuracy fold 1: 0.77046783625731, baseline: 0.5986842105263158\n",
      "Accuracy fold 2: 0.7470760233918129, baseline: 0.591374269005848\n",
      "Accuracy fold 3: 0.7534747622531089, baseline: 0.60424286759327\n",
      "Accuracy fold 4: 0.7556693489392831, baseline: 0.5874177029992684\n",
      "Accuracy fold 5: 0.7681053401609363, baseline: 0.5954645208485735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      4071\n",
      "           1       0.71      0.68      0.70      2766\n",
      "\n",
      "    accuracy                           0.76      6837\n",
      "   macro avg       0.75      0.75      0.75      6837\n",
      "weighted avg       0.76      0.76      0.76      6837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#importo le librerie per fare k-fold cross validation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#inizializzo k-fold\n",
    "splitter = KFold(n_splits=5, random_state=42, shuffle=True) #faccio 5-folds, utilizzo random_state 42 per la riproducibilit√†, e shuffle mescola i dati prima di distribuirli nei folds\n",
    "folds = list(splitter.split(X_train))\n",
    "\n",
    "#stampo le dimensioni dei folds per assicurarmi che tutto abbia funzionato correttamente\n",
    "for i in range(len(folds)):\n",
    "    print(len(folds[i][0]), len(folds[i][1]))\n",
    "    \n",
    "all_y_true = [] #etichette vere\n",
    "all_y_pred = [] #etichette predette\n",
    "\n",
    "for i in range(len(folds)): #itero sui folds generati prima\n",
    "    #prendo i dati di training e di test per l'attuale fold\n",
    "    train_ids = folds[i][0]\n",
    "    test_ids = folds[i][1]\n",
    "    \n",
    "    #creo training set e test set per l'attuale fold estrando le righe corrispondenti agli indici specificati in train_ids o test_ids\n",
    "    fold_X_train = [X_train[idx] for idx in train_ids]\n",
    "    fold_y_train = np.asarray([all_labels[idx] for idx in train_ids])\n",
    "    fold_X_test = [X_train[idx] for idx in test_ids]\n",
    "    fold_y_test = np.asarray([all_labels[idx] for idx in test_ids])\n",
    "    \n",
    "    #creo e addestro un svc sul training dell'attuale fold\n",
    "    kfold_svc = LinearSVC(dual=False)\n",
    "    kfold_svc.fit(fold_X_train, fold_y_train)\n",
    "    #faccio una predizione sul test dell'attuale fold\n",
    "    fold_y_pred = kfold_svc.predict(fold_X_test)\n",
    "    \n",
    "    #calcolo l'accuratezza dell'svc nel fold\n",
    "    fold_accuracy = accuracy_score(fold_y_test, fold_y_pred)\n",
    "    \n",
    "    #calcolo l'accuratezza nel fold anche di un dummy classifier con strategia most_frequent, per avere una baseline con cui confrontare l'accuratezza dell'svc\n",
    "    dummy_clf = DummyClassifier(strategy=\"most_frequent\")   # dummy classifier viene utilizzato per avere una baseline\n",
    "    dummy_clf.fit(fold_X_train, fold_y_train)\n",
    "    dummy_score = dummy_clf.score(fold_X_test, fold_y_test)\n",
    "    \n",
    "    #aggiungo le etichette vere e le etichette predette alle liste create inizialmente, per poter calcolare poi le metriche\n",
    "    all_y_true += fold_y_test.tolist()\n",
    "    all_y_pred += fold_y_pred.tolist()\n",
    "    \n",
    "    #stampo l'accuracy e la confronto con la baseline (l'accuracy del dummy classifier)\n",
    "    print(f\"Accuracy fold {i+1}: {fold_accuracy}, baseline: {dummy_score}\")\n",
    "    \n",
    "print(classification_report(all_y_true, all_y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae03b02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6837, 128)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tentativo 2, calcola la media dei word embeddings solo di aggettivi, nomi e verbi.\n",
    "all_features = extract_features(all_documents, \"filtered\")\n",
    "\n",
    "#stampo il numero dei documenti e il numero di features all'interno di uno per verificare che tutto sia andato correttamente\n",
    "len(all_features), len(all_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3efab18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6837, 128)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalizzo le features di train attraverso il MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(all_features)\n",
    "\n",
    "#stampo le dimensioni dell'array X_train per verificare che tutto sia andato correttamente\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18c378eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5469 1368\n",
      "5469 1368\n",
      "5470 1367\n",
      "5470 1367\n",
      "5470 1367\n",
      "Accuracy fold 1: 0.7368421052631579, baseline: 0.5986842105263158\n",
      "Accuracy fold 2: 0.7412280701754386, baseline: 0.591374269005848\n",
      "Accuracy fold 3: 0.7271397220190198, baseline: 0.60424286759327\n",
      "Accuracy fold 4: 0.7278712509144111, baseline: 0.5874177029992684\n",
      "Accuracy fold 5: 0.731528895391368, baseline: 0.5954645208485735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78      4071\n",
      "           1       0.68      0.63      0.66      2766\n",
      "\n",
      "    accuracy                           0.73      6837\n",
      "   macro avg       0.72      0.72      0.72      6837\n",
      "weighted avg       0.73      0.73      0.73      6837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#inizializzo k-fold\n",
    "splitter = KFold(n_splits=5, random_state=42, shuffle=True) #faccio 5-folds, utilizzo random_state 42 per la riproducibilit√†, e shuffle mescola i dati prima di distribuirli nei folds\n",
    "folds = list(splitter.split(X_train))\n",
    "\n",
    "#stampo le dimensioni dei folds per assicurarmi che tutto abbia funzionato correttamente\n",
    "for i in range(len(folds)):\n",
    "    print(len(folds[i][0]), len(folds[i][1]))\n",
    "    \n",
    "all_y_true = [] #etichette vere\n",
    "all_y_pred = [] #etichette predette\n",
    "\n",
    "for i in range(len(folds)): #itero sui folds generati prima\n",
    "    #prendo i dati di training e di test per l'attuale fold\n",
    "    train_ids = folds[i][0]\n",
    "    test_ids = folds[i][1]\n",
    "    \n",
    "    #creo training set e test set per l'attuale fold estrando le righe corrispondenti agli indici specificati in train_ids o test_ids\n",
    "    fold_X_train = [X_train[idx] for idx in train_ids]\n",
    "    fold_y_train = np.asarray([all_labels[idx] for idx in train_ids])\n",
    "    fold_X_test = [X_train[idx] for idx in test_ids]\n",
    "    fold_y_test = np.asarray([all_labels[idx] for idx in test_ids])\n",
    "    \n",
    "    #creo e addestro un svc sul training dell'attuale fold\n",
    "    kfold_svc = LinearSVC(dual=False)\n",
    "    kfold_svc.fit(fold_X_train, fold_y_train)\n",
    "    #faccio una predizione sul test dell'attuale fold\n",
    "    fold_y_pred = kfold_svc.predict(fold_X_test)\n",
    "    \n",
    "    #calcolo l'accuratezza dell'svc nel fold\n",
    "    fold_accuracy = accuracy_score(fold_y_test, fold_y_pred)\n",
    "    \n",
    "    #calcolo l'accuratezza nel fold anche di un dummy classifier con strategia most_frequent, per avere una baseline con cui confrontare l'accuratezza dell'svc\n",
    "    dummy_clf = DummyClassifier(strategy=\"most_frequent\")   # dummy classifier viene utilizzato per avere una baseline\n",
    "    dummy_clf.fit(fold_X_train, fold_y_train)\n",
    "    dummy_score = dummy_clf.score(fold_X_test, fold_y_test)\n",
    "    \n",
    "    #aggiungo le etichette vere e le etichette predette alle liste create inizialmente, per poter calcolare poi le metriche\n",
    "    all_y_true += fold_y_test.tolist()\n",
    "    all_y_pred += fold_y_pred.tolist()\n",
    "    \n",
    "    #stampo l'accuracy e la confronto con la baseline (l'accuracy del dummy classifier)\n",
    "    print(f\"Accuracy fold {i+1}: {fold_accuracy}, baseline: {dummy_score}\")\n",
    "    \n",
    "print(classification_report(all_y_true, all_y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5afc54dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6837, 384)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tentativo 3, calcola la media separatamente dei word embedding di aggettivi, nomi e verbi, e concatena i 3 vettori ottenuti.\n",
    "all_features = extract_features(all_documents, \"filtered_sep\")\n",
    "\n",
    "#stampo il numero dei documenti e il numero di features all'interno di uno per verificare che tutto sia andato correttamente\n",
    "len(all_features), len(all_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d74b2cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6837, 384)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalizzo le features di train attraverso il MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(all_features)\n",
    "\n",
    "#stampo le dimensioni dell'array X_train per verificare che tutto sia andato correttamente\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de986119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5469 1368\n",
      "5469 1368\n",
      "5470 1367\n",
      "5470 1367\n",
      "5470 1367\n",
      "Accuracy fold 1: 0.7258771929824561, baseline: 0.5986842105263158\n",
      "Accuracy fold 2: 0.7397660818713451, baseline: 0.591374269005848\n",
      "Accuracy fold 3: 0.7161667885881492, baseline: 0.60424286759327\n",
      "Accuracy fold 4: 0.7022677395757132, baseline: 0.5874177029992684\n",
      "Accuracy fold 5: 0.7205559619604974, baseline: 0.5954645208485735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      4071\n",
      "           1       0.67      0.62      0.64      2766\n",
      "\n",
      "    accuracy                           0.72      6837\n",
      "   macro avg       0.71      0.70      0.71      6837\n",
      "weighted avg       0.72      0.72      0.72      6837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#inizializzo k-fold\n",
    "splitter = KFold(n_splits=5, random_state=42, shuffle=True) #faccio 5-folds, utilizzo random_state 42 per la riproducibilit√†, e shuffle mescola i dati prima di distribuirli nei folds\n",
    "folds = list(splitter.split(X_train))\n",
    "\n",
    "#stampo le dimensioni dei folds per assicurarmi che tutto abbia funzionato correttamente\n",
    "for i in range(len(folds)):\n",
    "    print(len(folds[i][0]), len(folds[i][1]))\n",
    "    \n",
    "all_y_true = [] #etichette vere\n",
    "all_y_pred = [] #etichette predette\n",
    "\n",
    "for i in range(len(folds)): #itero sui folds generati prima\n",
    "    #prendo i dati di training e di test per l'attuale fold\n",
    "    train_ids = folds[i][0]\n",
    "    test_ids = folds[i][1]\n",
    "    \n",
    "    #creo training set e test set per l'attuale fold estrando le righe corrispondenti agli indici specificati in train_ids o test_ids\n",
    "    fold_X_train = [X_train[idx] for idx in train_ids]\n",
    "    fold_y_train = np.asarray([all_labels[idx] for idx in train_ids])\n",
    "    fold_X_test = [X_train[idx] for idx in test_ids]\n",
    "    fold_y_test = np.asarray([all_labels[idx] for idx in test_ids])\n",
    "    \n",
    "    #creo e addestro un svc sul training dell'attuale fold\n",
    "    kfold_svc = LinearSVC(dual=False)\n",
    "    kfold_svc.fit(fold_X_train, fold_y_train)\n",
    "    #faccio una predizione sul test dell'attuale fold\n",
    "    fold_y_pred = kfold_svc.predict(fold_X_test)\n",
    "    \n",
    "    #calcolo l'accuratezza dell'svc nel fold\n",
    "    fold_accuracy = accuracy_score(fold_y_test, fold_y_pred)\n",
    "    \n",
    "    #calcolo l'accuratezza nel fold anche di un dummy classifier con strategia most_frequent, per avere una baseline con cui confrontare l'accuratezza dell'svc\n",
    "    dummy_clf = DummyClassifier(strategy=\"most_frequent\")   # dummy classifier viene utilizzato per avere una baseline\n",
    "    dummy_clf.fit(fold_X_train, fold_y_train)\n",
    "    dummy_score = dummy_clf.score(fold_X_test, fold_y_test)\n",
    "    \n",
    "    #aggiungo le etichette vere e le etichette predette alle liste create inizialmente, per poter calcolare poi le metriche\n",
    "    all_y_true += fold_y_test.tolist()\n",
    "    all_y_pred += fold_y_pred.tolist()\n",
    "    \n",
    "    #stampo l'accuracy e la confronto con la baseline (l'accuracy del dummy classifier)\n",
    "    print(f\"Accuracy fold {i+1}: {fold_accuracy}, baseline: {dummy_score}\")\n",
    "    \n",
    "print(classification_report(all_y_true, all_y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ab9f60",
   "metadata": {},
   "source": [
    "Dei 3 tentativi, quello usando la media di tutti i word embeddings ha portato i migliori risultati in termini di prestazioni. Lo riportiamo dunque sui test set ufficiali del task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18de29a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#carico i miei test set dalla cartella con i file .conllu\n",
    "conllu_dir_test_1 = 'profiling_output_test_1/11936'\n",
    "conllu_dir_test_2 = 'profiling_output_test_2/11937'\n",
    "#inizializzo due liste che andr√≤ a riempire coi percorsi dei file .conllu\n",
    "all_documents_paths_test_1 = []\n",
    "all_documents_paths_test_2 = []\n",
    "#ottengo, per le due directory, una lista completa dei percorsi per accedere ai vari file\n",
    "for file_name in os.listdir(conllu_dir_test_1):\n",
    "    file_path = os.path.join(conllu_dir_test_1, file_name)\n",
    "    all_documents_paths_test_1.append(file_path)\n",
    "for file_name in os.listdir(conllu_dir_test_2):\n",
    "    file_path = os.path.join(conllu_dir_test_2, file_name)\n",
    "    all_documents_paths_test_2.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c891e23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'word': 'Il', 'pos': 'DET'},\n",
       "  {'word': 'manifesto', 'pos': 'NOUN'},\n",
       "  {'word': 'per', 'pos': 'ADP'},\n",
       "  {'word': 'gli', 'pos': 'DET'},\n",
       "  {'word': 'immigrati', 'pos': 'NOUN'},\n",
       "  {'word': ':', 'pos': 'PUNCT'},\n",
       "  {'word': '\\u200b\"', 'pos': 'PUNCT'},\n",
       "  {'word': 'Se', 'pos': 'SCONJ'},\n",
       "  {'word': 'sei', 'pos': 'AUX'},\n",
       "  {'word': 'venuto', 'pos': 'VERB'},\n",
       "  {'word': 'per', 'pos': 'ADP'},\n",
       "  {'word': 'delinquere', 'pos': 'VERB'},\n",
       "  {'word': 'faremo', 'pos': 'VERB'},\n",
       "  {'word': 'di', 'pos': 'ADP'},\n",
       "  {'word': 'tutto', 'pos': 'PRON'},\n",
       "  {'word': 'per', 'pos': 'ADP'},\n",
       "  {'word': 'cacciarti', 'pos': 'VERB'},\n",
       "  {'word': '\"', 'pos': 'PUNCT'}],\n",
       " [{'word': 'Mentre', 'pos': 'SCONJ'},\n",
       "  {'word': 'sto', 'pos': 'VERB'},\n",
       "  {'word': 'per', 'pos': 'ADP'},\n",
       "  {'word': 'mandarla', 'pos': 'NOUN'},\n",
       "  {'word': 'a', 'pos': 'ADP'},\n",
       "  {'word': 'fanculo', 'pos': 'NOUN'},\n",
       "  {'word': 'fa', 'pos': 'ADV'},\n",
       "  {'word': ':', 'pos': 'PUNCT'},\n",
       "  {'word': 'eh', 'pos': 'INTJ'},\n",
       "  {'word': 'pensi', 'pos': 'VERB'},\n",
       "  {'word': 'che', 'pos': 'SCONJ'},\n",
       "  {'word': 'mandiamo', 'pos': 'VERB'},\n",
       "  {'word': 'la', 'pos': 'DET'},\n",
       "  {'word': 'gente', 'pos': 'NOUN'},\n",
       "  {'word': 'a', 'pos': 'ADP'},\n",
       "  {'word': 'fare', 'pos': 'VERB'},\n",
       "  {'word': 'le', 'pos': 'DET'},\n",
       "  {'word': 'tonsille', 'pos': 'NOUN'},\n",
       "  {'word': 'a', 'pos': 'ADP'},\n",
       "  {'word': 'Brian√ßon', 'pos': 'PROPN'},\n",
       "  {'word': '!', 'pos': 'PUNCT'},\n",
       "  {'word': 'Questa', 'pos': 'PRON'},\n",
       "  {'word': '√®', 'pos': 'AUX'},\n",
       "  {'word': 'la', 'pos': 'DET'},\n",
       "  {'word': 'sanit√†', 'pos': 'NOUN'},\n",
       "  {'word': 'nel', 'pos': 'ADP'},\n",
       "  {'word': 'nord', 'pos': 'NOUN'},\n",
       "  {'word': 'Italia,a', 'pos': 'PROPN'},\n",
       "  {'word': 'furia', 'pos': 'VERB'},\n",
       "  {'word': 'di', 'pos': 'ADP'},\n",
       "  {'word': 'curare', 'pos': 'VERB'},\n",
       "  {'word': 'gratis', 'pos': 'ADV'},\n",
       "  {'word': 'immigrati', 'pos': 'ADJ'},\n",
       "  {'word': 'parassiti', 'pos': 'NOUN'},\n",
       "  {'word': 'di', 'pos': 'ADP'},\n",
       "  {'word': 'mezzo', 'pos': 'ADJ'},\n",
       "  {'word': 'mondo', 'pos': 'NOUN'},\n",
       "  {'word': '.', 'pos': 'PUNCT'},\n",
       "  {'word': 'Tu', 'pos': 'ADP'},\n",
       "  {'word': 'pagatore', 'pos': 'NOUN'},\n",
       "  {'word': 'di', 'pos': 'ADP'},\n",
       "  {'word': 'tasse', 'pos': 'NOUN'},\n",
       "  {'word': 'salate', 'pos': 'ADJ'},\n",
       "  {'word': ',', 'pos': 'PUNCT'},\n",
       "  {'word': 'sei', 'pos': 'AUX'},\n",
       "  {'word': 'obbligato', 'pos': 'VERB'},\n",
       "  {'word': 'di', 'pos': 'ADP'},\n",
       "  {'word': 'fatto', 'pos': 'NOUN'},\n",
       "  {'word': 'ad', 'pos': 'ADP'},\n",
       "  {'word': 'andare', 'pos': 'VERB'},\n",
       "  {'word': 'a', 'pos': 'ADP'},\n",
       "  {'word': 'pagamento', 'pos': 'NOUN'},\n",
       "  {'word': 'in', 'pos': 'ADP'},\n",
       "  {'word': 'clinica', 'pos': 'NOUN'}])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#due liste, una per ogni test set, che conterranno i tokens di ogni documento, per ora vuote\n",
    "all_documents_test_1 = []\n",
    "all_documents_test_2 = []\n",
    "\n",
    "#estraggo tutti i tokens da ogni documento di all_documents_path_test_1 e li appendo nella lista all_documents_test_1\n",
    "for document_path in all_documents_paths_test_1:\n",
    "    document_tokens = get_tokens_from_file(document_path)\n",
    "    all_documents_test_1.append(document_tokens)\n",
    "    \n",
    "#estraggo tutti i tokens da ogni documento di all_documents_path_test_2 e li appendo nella lista all_documents_test_2\n",
    "for document_path in all_documents_paths_test_2:\n",
    "    document_tokens = get_tokens_from_file(document_path)\n",
    "    all_documents_test_2.append(document_tokens)\n",
    "    \n",
    "#stampo tutti i tokens dei due documenti alla posizione 50 per verificare che tutto sia stato eseguito correttamente\n",
    "all_documents_test_1[50], all_documents_test_2[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ba242bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6837, 128)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#addestro un svc lineare sul mio sistema migliore in modo da poterlo testare sui test set ufficiali\n",
    "\n",
    "all_features = extract_features(all_documents, \"all\")\n",
    "#stampo il numero dei documenti e il numero di features all'interno di uno per verificare che tutto sia andato correttamente\n",
    "len(all_features), len(all_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e32242ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '0', '0', '1', '1', '0', '0', '1', '0', '1', '0', '1', '0', '0', '1']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creo la lista delle labels e ne stampo 15 per vedere se tutto √® andato a buon fine\n",
    "all_labels = create_label_list(all_documents_paths)\n",
    "all_labels[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed5777a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6837, 128)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalizzo tutte le features attraverso il MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "all_features = scaler.fit_transform(all_features)\n",
    "\n",
    "#stampo le dimensioni dell'array all_features.shape per verificare che tutto sia andato correttamente\n",
    "all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c55c77fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(dual=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearSVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.LinearSVC.html\">?<span>Documentation for LinearSVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC(dual=False)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(dual=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modello svc lineare\n",
    "svc_model = LinearSVC(dual=False)\n",
    "#addestro il modello sui dati di train\n",
    "svc_model.fit(all_features, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c66911ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 128), (1263, 128))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#estraggo le features dai documenti di test\n",
    "all_features_test_1 = extract_features(all_documents_test_1, \"all\")\n",
    "all_features_test_2 = extract_features(all_documents_test_2, \"all\")\n",
    "\n",
    "#normalizzo le features con il MinMaxScaler gi√† fittato sui dati di train\n",
    "all_features_test_1 = scaler.transform(all_features_test_1)\n",
    "all_features_test_2 = scaler.transform(all_features_test_2)\n",
    "\n",
    "#stampo le dimensioni degli array per verificare che tutto sia andato correttamente\n",
    "all_features_test_1.shape, all_features_test_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c88cc50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['0', '0', '0', '1', '1', '1', '1', '0', '0', '1', '0', '0', '0', '1', '0'],\n",
       " ['1', '1', '1', '1', '0', '0', '1', '1', '0', '1', '1', '0', '1', '1', '0'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creo la lista delle labels per i due test sets\n",
    "all_labels_test_1 = create_label_list(all_documents_paths_test_1)\n",
    "all_labels_test_2 = create_label_list(all_documents_paths_test_2)\n",
    "\n",
    "#stampo 15 labels per ogni test set in modo da garantire che tutto sia andato correttamente\n",
    "all_labels_test_1[:15], all_labels_test_2[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a67677b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.95      0.82       319\n",
      "           1       0.80      0.37      0.51       181\n",
      "\n",
      "    accuracy                           0.74       500\n",
      "   macro avg       0.76      0.66      0.66       500\n",
      "weighted avg       0.75      0.74      0.71       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predizione sul test1\n",
    "y_pred_test_1 = svc_model.predict(all_features_test_1) #predicto sull'svc_model gi√† fittato ai dati di train\n",
    "print(classification_report(all_labels_test_1, y_pred_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dcbacf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74       641\n",
      "           1       0.74      0.72      0.73       622\n",
      "\n",
      "    accuracy                           0.74      1263\n",
      "   macro avg       0.74      0.74      0.74      1263\n",
      "weighted avg       0.74      0.74      0.74      1263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predizione sul test2\n",
    "y_pred_test_2 = svc_model.predict(all_features_test_2) #predicto sull'svc_model gi√† fittato ai dati di train\n",
    "print(classification_report(all_labels_test_2, y_pred_test_2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
