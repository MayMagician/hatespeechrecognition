{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4bdfb58",
   "metadata": {},
   "source": [
    "Basato su EVALITA 2020 HaSpeeDe (http://www.di.unito.it/~tutreeb/haspeede-evalita20/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475a9691",
   "metadata": {},
   "source": [
    "Sviluppare un classificatore basato su SVM lineari che prende in input una rappresentazione del testo basata su n-grammi di caratteri, parole e part-of-speech. Riportare i seguenti risultati:\n",
    "- Testare diverse rappresentazioni del testo che variano rispetto alla lunghezza degli ngrammi utilizzati e/o rispetto al tipo di informazione utilizzata all’interno degli ngrammi (forme, lemmi, caratteri, part-of-speech) e valutare i diversi sistemi con un processo di 5-fold cross validation condotto sul training set;\n",
    "- Valutazione sul test set ufficiale del miglior sistema rispetto ai risultati ottenuti con il processo di 5-fold cross validation del punto sopra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867a674f",
   "metadata": {},
   "source": [
    "I file delle annotazioni linguistiche sono già stati estratti tramite Profiling-UD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce57c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#path alla cartella in cui sono presenti i file .conllu per il training set da 6383 elementi\n",
    "conllu_dir = 'profiling_output/11925/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6afee573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inizio col definire le classi document, sentence e token \n",
    "class Document: #un documento è una lista di frasi\n",
    "    #inizializza il percorso, chiama parse_doc_info per estrarre info dal nome del file. poi inizializza due variabili per estrarre informazioni dal documento: lista di frasi e features\n",
    "    def __init__(self, document_path):\n",
    "        self.document_path = document_path\n",
    "        self._parse_doc_info(document_path)\n",
    "        self.sentences = []\n",
    "        self.features = None\n",
    "    #estrae id e hs dal nome del file\n",
    "    def _parse_doc_info(self, document_path):\n",
    "        document_path = document_path.split('/')[-1]\n",
    "        document_info = document_path.split('.')[0]\n",
    "        #splitto la stringa del nome del file in una lista che ha come primo elemento (prima del #) l'id e come secondo (dopo il #) l'hs (0 se non contiene hs, 1 se lo contiene)\n",
    "        document_info = document_info.split('#')\n",
    "        self.id = document_info[0]\n",
    "        self.hs = document_info[1]\n",
    "    #aggiunge una frase alla lista delle frasi         \n",
    "    def add_sentence(self, sentences):\n",
    "        self.sentences.append(sentences)\n",
    "    #restituisce il numero di token totali del documento   \n",
    "    def get_num_tokens(self):\n",
    "        num_words = 0\n",
    "        for sentence in self.sentences:\n",
    "            num_words = num_words + sentence.get_num_tokens()\n",
    "        return num_words\n",
    "    #restituisce il numero totale di caratteri del documento\n",
    "    def get_num_chars(self):\n",
    "        num_chars = 0\n",
    "        for sentence in self.sentences:\n",
    "            sentence_char_len = sentence.get_num_chars()\n",
    "            num_chars = num_chars + sentence_char_len\n",
    "        return num_chars\n",
    "        \n",
    "class Sentence: #una frase è una lista di token\n",
    "    #inizializza la lista di token\n",
    "    def __init__(self):\n",
    "        self.tokens = []\n",
    "    #aggiunge un token alla lista di token \n",
    "    def add_token(self, token):\n",
    "        self.tokens.append(token)\n",
    "    #restituisce la lista delle parole token (token presi una volta sola, non ripetuti) nella frase\n",
    "    def get_words(self):\n",
    "        return [token.word for token in self.tokens]\n",
    "    #restituisce la lista dei lemmi nella frase\n",
    "    def get_lemmas(self):\n",
    "        return [token.lemma for token in self.tokens]\n",
    "    #restituisce la lista dei POS nella frase\n",
    "    def get_pos(self):\n",
    "        return [token.pos for token in self.tokens]\n",
    "    #restituisce il numero di token nella frase\n",
    "    def get_num_tokens(self):\n",
    "        return len(self.tokens)\n",
    "    #restituisce il numero totale di caratteri nella frase (spazi inclusi, come specificato)\n",
    "    def get_num_chars(self):\n",
    "        num_chars = 0\n",
    "        for token in self.tokens:\n",
    "            num_chars = num_chars + token.get_num_chars()\n",
    "        num_chars = num_chars + self.get_num_tokens() - 1 # contiamo anche gli spazi\n",
    "        return num_chars\n",
    "    #restituisce rappresentazione stringa della frase combinando tutti i token, separati da spazi\n",
    "    def __str__(self):\n",
    "        return ' '.join([token.word for token in self.tokens])\n",
    "\n",
    "class Token: #è un singolo token\n",
    "    #inizializza la parola token, il lemma e il POS\n",
    "    def __init__(self, word, lemma, pos):\n",
    "        self.word = word\n",
    "        self.lemma = lemma\n",
    "        self.pos = pos\n",
    "    #restituisce il numero di caratteri della parola token\n",
    "    def get_num_chars(self):\n",
    "        return len(self.word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d88c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#carica un documento leggendone frasi e token\n",
    "def load_document_sentences(document):\n",
    "    sentence = Sentence()\n",
    "    for line in open(document.document_path, 'r'): #cicla sulle righe del file\n",
    "        if line[0].isdigit():  #controlla se la riga inizia con un numero perché vorrebbe dire che siamo davanti a un token nel caso di un file .conllu\n",
    "            splitted_line = line.strip().split('\\t')\n",
    "            if '-' not in splitted_line[0]:  #se l'id della parola non contiene un trattino (tutti gli id non dovrebbero contenere trattini)\n",
    "                token = Token(splitted_line[1], splitted_line[2], splitted_line[3])\n",
    "                #aggiunge il token alla frase\n",
    "                sentence.add_token(token)\n",
    "        if line == '\\n':  #se la riga è vuota significa che la frase è finita\n",
    "            #aggiunge la frase al documento\n",
    "            document.add_sentence(sentence)\n",
    "            #inizializza una nuova frase\n",
    "            sentence = Sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d65527d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#legge tutti i file di una cartella\n",
    "all_documents = [] #inizializza la lista dei documenti, per ora vuota\n",
    "for file_name in os.listdir(conllu_dir): #itera i file nella cartella\n",
    "    file_path = os.path.join(conllu_dir, file_name)\n",
    "    #per ogni file, crea un oggetto Document\n",
    "    document = Document(file_path)\n",
    "    #utilizza la funzione load_document_sentences per caricare il documento leggendone frasi e token\n",
    "    load_document_sentences(document)\n",
    "    #aggiunge il documento alla lista dei documenti\n",
    "    all_documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00916b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione per estrarre n-grammi da una frase: el può essere \"word\" per n-grammi di parole, \"lemma\" per n-grammi di lemmi o \"pos\" per n-grammi di pos\n",
    "def extract_word_ngrams_from_sentence(word_ngrams, sentence, el, n): #word_ngrams è un dizionario di n-grammi (n-grammi chiavi, numero di volte in cui appaiono valori)\n",
    "    #crea una lista con tutte le parole\n",
    "    if el == 'word':\n",
    "        all_words = sentence.get_words()\n",
    "    elif el == 'lemma':\n",
    "        all_words = sentence.get_lemmas()\n",
    "    elif el == 'pos':\n",
    "        all_words = sentence.get_pos()\n",
    "    else:\n",
    "        raise Exception(f'Invalid element {el}')\n",
    "    #all_words è la lista delle parole, dei lemmi o dei pos\n",
    "\n",
    "    #scorre la lista delle parole ed estrae gli n-grammi\n",
    "    for i in range(0, len(all_words) - n + 1): #-n+1 serve per non uscire dal vettore\n",
    "        ngram_words = all_words[i: i + n]\n",
    "        ngram = f'{el.upper()}_{n}_' + '_'.join(ngram_words) #crea l'n-gramma come stringa\n",
    "        if ngram not in word_ngrams: #aggiunge l'n-gramma al dizionario, o aumenta di 1 il suo valore se già presente\n",
    "            word_ngrams[ngram] = 1\n",
    "        else:\n",
    "            word_ngrams[ngram] += 1\n",
    "    #ritorna il dizionario\n",
    "    return word_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "516ac323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione per estrarre n-grammi di caratteri da una frase\n",
    "def extract_char_ngrams_from_sentence(char_ngrams, sentence, n):\n",
    "    #crea una lista con tutte le parole\n",
    "    all_words = sentence.get_words()\n",
    "    #crea una stringa che contenga tutte le parole separate tra spazi perchè vogliamo scorrere i caratteri\n",
    "    all_words = ' '.join(all_words)\n",
    "\n",
    "    #scorre la stringa ed estrae gli n-grammi di caratteri\n",
    "    for i in range(0, len(all_words) - n + 1):\n",
    "        ngram_chars = all_words[i:i + n]\n",
    "        ngram = f'CHAR_{n}_' + ngram_chars #crea l'n-gramma come stringa\n",
    "        if ngram not in char_ngrams: #aggiunge l'n-gramma al dizionario, o aumenta di 1 il suo valore se già presente\n",
    "            char_ngrams[ngram] = 1\n",
    "        else:\n",
    "            char_ngrams[ngram] += 1\n",
    "    #ritorna il dizionario\n",
    "    return char_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21db9068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#per ogni documento, estrae n-grammi di parole e/o di caratteri e li memorizza come attributo features, normalizzandoli\n",
    "def normalize_ngrams(ngrams_dict, doc_len):\n",
    "    for ngram in ngrams_dict:\n",
    "        ngrams_dict[ngram] = ngrams_dict[ngram] / float(doc_len)\n",
    "\n",
    "#ngram_type può essere \"word\", \"lemma\", \"pos\" o \"char\"; ngram_number può essere qualsiasi numero da 1 in su\n",
    "def extract_documents_ngrams_normalized(all_documents, ngram_type, ngram_number):\n",
    "    #controllo che ngram_number sia 1 o più\n",
    "    if ngram_number < 1:\n",
    "        raise Exception(f'Invalid element {ngram_number}')\n",
    "    \n",
    "    for document in all_documents:\n",
    "        \n",
    "        ngrams = dict()\n",
    "        \n",
    "        for sentence in document.sentences:\n",
    "            if ngram_type in [\"word\", \"lemma\", \"pos\"]:\n",
    "                extract_word_ngrams_from_sentence(ngrams, sentence, ngram_type, ngram_number)\n",
    "                num_words = document.get_num_tokens()\n",
    "                normalize_ngrams(ngrams, num_words)\n",
    "            elif ngram_type == \"char\":\n",
    "                extract_char_ngrams_from_sentence(ngrams, sentence, ngram_number)\n",
    "                num_chars = document.get_num_chars()\n",
    "                normalize_ngrams(ngrams, num_chars)\n",
    "\n",
    "        document.features = ngrams\n",
    "#alla fine, ogni documento della lista all_documents avrà un attributo features contenente un dizionario di n-grammi normalizzati."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff7bcb2",
   "metadata": {},
   "source": [
    "### Rappresentazione del testo basata su bigrammi di parole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa9b4b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_documents_ngrams_normalized(all_documents, \"word\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dd2326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [document.features for document in all_documents]\n",
    "labels = [document.hs for document in all_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2c820ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero features iniziali: 98227\n",
      "Numero features dopo il filtro: 4036\n"
     ]
    }
   ],
   "source": [
    "#filtro le features rimuovendo quelle che compaiono meno di \"min_occurencies\"\n",
    "\n",
    "def get_num_features(features_dict):\n",
    "    all_features = set()\n",
    "    for document_feats in features_dict:\n",
    "        all_features.update(list(document_feats.keys()))\n",
    "    return len(all_features)\n",
    "\n",
    "def filter_features(train_features_dict, min_occurrences):\n",
    "    #contiamo ogni feature in quanti dcoumenti diversi compare\n",
    "    features_counter = dict()\n",
    "    for document_features_dict in train_features_dict:\n",
    "        for feature in document_features_dict:\n",
    "            if feature in features_counter:\n",
    "                features_counter[feature] += 1\n",
    "            else:\n",
    "                features_counter[feature] = 1\n",
    "\n",
    "    #per ogni documento, togliamo le features che compaiono meno di \"min_occurrences\"\n",
    "    for document_features_dict in train_features_dict:\n",
    "        document_features = list(document_features_dict.keys())\n",
    "        for feature in document_features:\n",
    "            if features_counter[feature] < min_occurrences:\n",
    "                document_features_dict.pop(feature)\n",
    "\n",
    "    return features\n",
    "\n",
    "print(f'Numero features iniziali: {get_num_features(features)}')\n",
    "\n",
    "#applico il filtro mettendo min_occurencies a 5\n",
    "features = filter_features(features, 5)\n",
    "\n",
    "print(f'Numero features dopo il filtro: {get_num_features(features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e132af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5469 1368\n",
      "5469 1368\n",
      "5470 1367\n",
      "5470 1367\n",
      "5470 1367\n",
      "Accuracy fold 1: 0.618421052631579, baseline: 0.5986842105263158\n",
      "Accuracy fold 2: 0.6089181286549707, baseline: 0.591374269005848\n",
      "Accuracy fold 3: 0.6254572055596196, baseline: 0.60424286759327\n",
      "Accuracy fold 4: 0.6057059253840527, baseline: 0.5874177029992684\n",
      "Accuracy fold 5: 0.6100950987564009, baseline: 0.5954645208485735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.99      0.75      4071\n",
      "           1       0.78      0.06      0.12      2766\n",
      "\n",
      "    accuracy                           0.61      6837\n",
      "   macro avg       0.69      0.53      0.44      6837\n",
      "weighted avg       0.68      0.61      0.50      6837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#importo le librerie per fare k-fold cross validation\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "#inizializzo il vettorizzatore per ottenere poi delle matrici numeriche\n",
    "vectorizer = DictVectorizer()\n",
    "\n",
    "#inizializzo k-fold\n",
    "splitter = KFold(n_splits=5, random_state=42, shuffle=True) #faccio 5-folds, utilizzo random_state 42 per la riproducibilità, e shuffle mescola i dati prima di distribuirli nei folds\n",
    "folds = list(splitter.split(features))\n",
    "\n",
    "#stampo le dimensioni dei folds per assicurarmi che tutto abbia funzionato correttamente\n",
    "for i in range(len(folds)):\n",
    "    print(len(folds[i][0]), len(folds[i][1]))\n",
    "    \n",
    "all_y_true = [] #etichette vere\n",
    "all_y_pred = [] #etichette predette\n",
    "\n",
    "for i in range(len(folds)): #itero sui folds generati prima\n",
    "    #prendo i dati di training e di test per l'attuale fold\n",
    "    train_ids = folds[i][0]\n",
    "    test_ids = folds[i][1]\n",
    "    \n",
    "    #creo training set e test set per l'attuale fold estrando le righe corrispondenti agli indici specificati in train_ids o test_ids\n",
    "    fold_X_train = [features[idx] for idx in train_ids]\n",
    "    fold_y_train = np.asarray([labels[idx] for idx in train_ids])\n",
    "    fold_X_test = [features[idx] for idx in test_ids]\n",
    "    fold_y_test = np.asarray([labels[idx] for idx in test_ids])\n",
    "    \n",
    "    #uso dict_vectorizer per trasformare fold_X_train e fold_X_test in matrici numeriche (verranno sparse)\n",
    "    fold_X_train = vectorizer.fit_transform(fold_X_train)\n",
    "    fold_X_test = vectorizer.transform(fold_X_test)\n",
    "    \n",
    "    #creo e addestro un svc sul training dell'attuale fold\n",
    "    kfold_svc = LinearSVC(dual=False)\n",
    "    kfold_svc.fit(fold_X_train, fold_y_train)\n",
    "    #faccio una predizione sul test dell'attuale fold\n",
    "    fold_y_pred = kfold_svc.predict(fold_X_test)\n",
    "    \n",
    "    #calcolo l'accuratezza dell'svc nel fold\n",
    "    fold_accuracy = accuracy_score(fold_y_test, fold_y_pred)\n",
    "    \n",
    "    #calcolo l'accuratezza nel fold anche di un dummy classifier con strategia most_frequent, per avere una baseline con cui confrontare l'accuratezza dell'svc\n",
    "    dummy_clf = DummyClassifier(strategy=\"most_frequent\")   # dummy classifier viene utilizzato per avere una baseline\n",
    "    dummy_clf.fit(fold_X_train, fold_y_train)\n",
    "    dummy_score = dummy_clf.score(fold_X_test, fold_y_test)\n",
    "    \n",
    "    #aggiungo le etichette vere e le etichette predette alle liste create inizialmente, per poter calcolare poi le metriche\n",
    "    all_y_true += fold_y_test.tolist()\n",
    "    all_y_pred += fold_y_pred.tolist()\n",
    "    \n",
    "    #stampo l'accuracy e la confronto con la baseline (l'accuracy del dummy classifier)\n",
    "    print(f\"Accuracy fold {i+1}: {fold_accuracy}, baseline: {dummy_score}\")\n",
    "    \n",
    "print(classification_report(all_y_true, all_y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bc1f3b",
   "metadata": {},
   "source": [
    "Riapplico adesso la stessa procedura appena utilizza per le rappresentazioni basate su bigrammi di lemmi, POS e caratteri."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eddcd8",
   "metadata": {},
   "source": [
    "### Rappresentazione del testo basata su bigrammi di lemmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a67778df",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_documents_ngrams_normalized(all_documents, \"lemma\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "714e8e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [document.features for document in all_documents]\n",
    "labels = [document.hs for document in all_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f9e6f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero features iniziali: 82536\n",
      "Numero features dopo il filtro: 4504\n"
     ]
    }
   ],
   "source": [
    "print(f'Numero features iniziali: {get_num_features(features)}')\n",
    "\n",
    "#applico il filtro mettendo min_occurencies a 5\n",
    "features = filter_features(features, 5)\n",
    "\n",
    "print(f'Numero features dopo il filtro: {get_num_features(features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15eec3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5469 1368\n",
      "5469 1368\n",
      "5470 1367\n",
      "5470 1367\n",
      "5470 1367\n",
      "Accuracy fold 1: 0.6264619883040936, baseline: 0.5986842105263158\n",
      "Accuracy fold 2: 0.6220760233918129, baseline: 0.591374269005848\n",
      "Accuracy fold 3: 0.6313094367227505, baseline: 0.60424286759327\n",
      "Accuracy fold 4: 0.6166788588149232, baseline: 0.5874177029992684\n",
      "Accuracy fold 5: 0.6217995610826628, baseline: 0.5954645208485735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.98      0.76      4071\n",
      "           1       0.75      0.11      0.18      2766\n",
      "\n",
      "    accuracy                           0.62      6837\n",
      "   macro avg       0.68      0.54      0.47      6837\n",
      "weighted avg       0.67      0.62      0.52      6837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#inizializzo il vettorizzatore per ottenere poi delle matrici numeriche\n",
    "vectorizer = DictVectorizer()\n",
    "\n",
    "#inizializzo k-fold\n",
    "splitter = KFold(n_splits=5, random_state=42, shuffle=True) #faccio 5-folds, utilizzo random_state 42 per la riproducibilità, e shuffle mescola i dati prima di distribuirli nei folds\n",
    "folds = list(splitter.split(features))\n",
    "\n",
    "#stampo le dimensioni dei folds per assicurarmi che tutto abbia funzionato correttamente\n",
    "for i in range(len(folds)):\n",
    "    print(len(folds[i][0]), len(folds[i][1]))\n",
    "    \n",
    "all_y_true = [] #etichette vere\n",
    "all_y_pred = [] #etichette predette\n",
    "\n",
    "for i in range(len(folds)): #itero sui folds generati prima\n",
    "    #prendo i dati di training e di test per l'attuale fold\n",
    "    train_ids = folds[i][0]\n",
    "    test_ids = folds[i][1]\n",
    "    \n",
    "    #creo training set e test set per l'attuale fold estrando le righe corrispondenti agli indici specificati in train_ids o test_ids\n",
    "    fold_X_train = [features[idx] for idx in train_ids]\n",
    "    fold_y_train = np.asarray([labels[idx] for idx in train_ids])\n",
    "    fold_X_test = [features[idx] for idx in test_ids]\n",
    "    fold_y_test = np.asarray([labels[idx] for idx in test_ids])\n",
    "    \n",
    "    #uso dict_vectorizer per trasformare fold_X_train e fold_X_test in matrici numeriche (verranno sparse)\n",
    "    fold_X_train = vectorizer.fit_transform(fold_X_train)\n",
    "    fold_X_test = vectorizer.transform(fold_X_test)\n",
    "    \n",
    "    #creo e addestro un svc sul training dell'attuale fold\n",
    "    kfold_svc = LinearSVC(dual=False)\n",
    "    kfold_svc.fit(fold_X_train, fold_y_train)\n",
    "    #faccio una predizione sul test dell'attuale fold\n",
    "    fold_y_pred = kfold_svc.predict(fold_X_test)\n",
    "    \n",
    "    #calcolo l'accuratezza dell'svc nel fold\n",
    "    fold_accuracy = accuracy_score(fold_y_test, fold_y_pred)\n",
    "    \n",
    "    #calcolo l'accuratezza nel fold anche di un dummy classifier con strategia most_frequent, per avere una baseline con cui confrontare l'accuratezza dell'svc\n",
    "    dummy_clf = DummyClassifier(strategy=\"most_frequent\")   # dummy classifier viene utilizzato per avere una baseline\n",
    "    dummy_clf.fit(fold_X_train, fold_y_train)\n",
    "    dummy_score = dummy_clf.score(fold_X_test, fold_y_test)\n",
    "    \n",
    "    #aggiungo le etichette vere e le etichette predette alle liste create inizialmente, per poter calcolare poi le metriche\n",
    "    all_y_true += fold_y_test.tolist()\n",
    "    all_y_pred += fold_y_pred.tolist()\n",
    "    \n",
    "    #stampo l'accuracy e la confronto con la baseline (l'accuracy del dummy classifier)\n",
    "    print(f\"Accuracy fold {i+1}: {fold_accuracy}, baseline: {dummy_score}\")\n",
    "    \n",
    "print(classification_report(all_y_true, all_y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94c13b2",
   "metadata": {},
   "source": [
    "### Rappresentazione del testo basata su bigrammi di POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e03f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_documents_ngrams_normalized(all_documents, \"pos\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1b2d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [document.features for document in all_documents]\n",
    "labels = [document.hs for document in all_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d0b5f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero features iniziali: 246\n",
      "Numero features dopo il filtro: 229\n"
     ]
    }
   ],
   "source": [
    "print(f'Numero features iniziali: {get_num_features(features)}')\n",
    "\n",
    "#applico il filtro mettendo min_occurencies a 5\n",
    "features = filter_features(features, 5)\n",
    "\n",
    "print(f'Numero features dopo il filtro: {get_num_features(features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8932e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5469 1368\n",
      "5469 1368\n",
      "5470 1367\n",
      "5470 1367\n",
      "5470 1367\n",
      "Accuracy fold 1: 0.6352339181286549, baseline: 0.5986842105263158\n",
      "Accuracy fold 2: 0.6308479532163743, baseline: 0.591374269005848\n",
      "Accuracy fold 3: 0.6269202633504023, baseline: 0.60424286759327\n",
      "Accuracy fold 4: 0.6188734455010972, baseline: 0.5874177029992684\n",
      "Accuracy fold 5: 0.6269202633504023, baseline: 0.5954645208485735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.89      0.74      4071\n",
      "           1       0.60      0.25      0.35      2766\n",
      "\n",
      "    accuracy                           0.63      6837\n",
      "   macro avg       0.62      0.57      0.54      6837\n",
      "weighted avg       0.62      0.63      0.58      6837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#inizializzo il vettorizzatore per ottenere poi delle matrici numeriche\n",
    "vectorizer = DictVectorizer()\n",
    "\n",
    "#inizializzo k-fold\n",
    "splitter = KFold(n_splits=5, random_state=42, shuffle=True) #faccio 5-folds, utilizzo random_state 42 per la riproducibilità, e shuffle mescola i dati prima di distribuirli nei folds\n",
    "folds = list(splitter.split(features))\n",
    "\n",
    "#stampo le dimensioni dei folds per assicurarmi che tutto abbia funzionato correttamente\n",
    "for i in range(len(folds)):\n",
    "    print(len(folds[i][0]), len(folds[i][1]))\n",
    "    \n",
    "all_y_true = [] #etichette vere\n",
    "all_y_pred = [] #etichette predette\n",
    "\n",
    "for i in range(len(folds)): #itero sui folds generati prima\n",
    "    #prendo i dati di training e di test per l'attuale fold\n",
    "    train_ids = folds[i][0]\n",
    "    test_ids = folds[i][1]\n",
    "    \n",
    "    #creo training set e test set per l'attuale fold estrando le righe corrispondenti agli indici specificati in train_ids o test_ids\n",
    "    fold_X_train = [features[idx] for idx in train_ids]\n",
    "    fold_y_train = np.asarray([labels[idx] for idx in train_ids])\n",
    "    fold_X_test = [features[idx] for idx in test_ids]\n",
    "    fold_y_test = np.asarray([labels[idx] for idx in test_ids])\n",
    "    \n",
    "    #uso dict_vectorizer per trasformare fold_X_train e fold_X_test in matrici numeriche (verranno sparse)\n",
    "    fold_X_train = vectorizer.fit_transform(fold_X_train)\n",
    "    fold_X_test = vectorizer.transform(fold_X_test)\n",
    "    \n",
    "    #creo e addestro un svc sul training dell'attuale fold\n",
    "    kfold_svc = LinearSVC(dual=False)\n",
    "    kfold_svc.fit(fold_X_train, fold_y_train)\n",
    "    #faccio una predizione sul test dell'attuale fold\n",
    "    fold_y_pred = kfold_svc.predict(fold_X_test)\n",
    "    \n",
    "    #calcolo l'accuratezza dell'svc nel fold\n",
    "    fold_accuracy = accuracy_score(fold_y_test, fold_y_pred)\n",
    "    \n",
    "    #calcolo l'accuratezza nel fold anche di un dummy classifier con strategia most_frequent, per avere una baseline con cui confrontare l'accuratezza dell'svc\n",
    "    dummy_clf = DummyClassifier(strategy=\"most_frequent\")   # dummy classifier viene utilizzato per avere una baseline\n",
    "    dummy_clf.fit(fold_X_train, fold_y_train)\n",
    "    dummy_score = dummy_clf.score(fold_X_test, fold_y_test)\n",
    "    \n",
    "    #aggiungo le etichette vere e le etichette predette alle liste create inizialmente, per poter calcolare poi le metriche\n",
    "    all_y_true += fold_y_test.tolist()\n",
    "    all_y_pred += fold_y_pred.tolist()\n",
    "    \n",
    "    #stampo l'accuracy e la confronto con la baseline (l'accuracy del dummy classifier)\n",
    "    print(f\"Accuracy fold {i+1}: {fold_accuracy}, baseline: {dummy_score}\")\n",
    "    \n",
    "print(classification_report(all_y_true, all_y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311778e3",
   "metadata": {},
   "source": [
    "### Rappresentazione del testo basata su bigrammi di caratteri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a053951",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_documents_ngrams_normalized(all_documents, \"char\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5029cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [document.features for document in all_documents]\n",
    "labels = [document.hs for document in all_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8805cd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero features iniziali: 3390\n",
      "Numero features dopo il filtro: 1441\n"
     ]
    }
   ],
   "source": [
    "print(f'Numero features iniziali: {get_num_features(features)}')\n",
    "\n",
    "#applico il filtro mettendo min_occurencies a 5\n",
    "features = filter_features(features, 5)\n",
    "\n",
    "print(f'Numero features dopo il filtro: {get_num_features(features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89d3117f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5469 1368\n",
      "5469 1368\n",
      "5470 1367\n",
      "5470 1367\n",
      "5470 1367\n",
      "Accuracy fold 1: 0.6827485380116959, baseline: 0.5986842105263158\n",
      "Accuracy fold 2: 0.6637426900584795, baseline: 0.591374269005848\n",
      "Accuracy fold 3: 0.6583760058522312, baseline: 0.60424286759327\n",
      "Accuracy fold 4: 0.6561814191660571, baseline: 0.5874177029992684\n",
      "Accuracy fold 5: 0.6561814191660571, baseline: 0.5954645208485735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.92      0.76      4071\n",
      "           1       0.71      0.29      0.41      2766\n",
      "\n",
      "    accuracy                           0.66      6837\n",
      "   macro avg       0.68      0.60      0.59      6837\n",
      "weighted avg       0.68      0.66      0.62      6837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#inizializzo il vettorizzatore per ottenere poi delle matrici numeriche\n",
    "vectorizer = DictVectorizer()\n",
    "\n",
    "#inizializzo k-fold\n",
    "splitter = KFold(n_splits=5, random_state=42, shuffle=True) #faccio 5-folds, utilizzo random_state 42 per la riproducibilità, e shuffle mescola i dati prima di distribuirli nei folds\n",
    "folds = list(splitter.split(features))\n",
    "\n",
    "#stampo le dimensioni dei folds per assicurarmi che tutto abbia funzionato correttamente\n",
    "for i in range(len(folds)):\n",
    "    print(len(folds[i][0]), len(folds[i][1]))\n",
    "    \n",
    "all_y_true = [] #etichette vere\n",
    "all_y_pred = [] #etichette predette\n",
    "\n",
    "for i in range(len(folds)): #itero sui folds generati prima\n",
    "    #prendo i dati di training e di test per l'attuale fold\n",
    "    train_ids = folds[i][0]\n",
    "    test_ids = folds[i][1]\n",
    "    \n",
    "    #creo training set e test set per l'attuale fold estrando le righe corrispondenti agli indici specificati in train_ids o test_ids\n",
    "    fold_X_train = [features[idx] for idx in train_ids]\n",
    "    fold_y_train = np.asarray([labels[idx] for idx in train_ids])\n",
    "    fold_X_test = [features[idx] for idx in test_ids]\n",
    "    fold_y_test = np.asarray([labels[idx] for idx in test_ids])\n",
    "    \n",
    "    #uso dict_vectorizer per trasformare fold_X_train e fold_X_test in matrici numeriche (verranno sparse)\n",
    "    fold_X_train = vectorizer.fit_transform(fold_X_train)\n",
    "    fold_X_test = vectorizer.transform(fold_X_test)\n",
    "    \n",
    "    #creo e addestro un svc sul training dell'attuale fold\n",
    "    kfold_svc = LinearSVC(dual=False)\n",
    "    kfold_svc.fit(fold_X_train, fold_y_train)\n",
    "    #faccio una predizione sul test dell'attuale fold\n",
    "    fold_y_pred = kfold_svc.predict(fold_X_test)\n",
    "    \n",
    "    #calcolo l'accuratezza dell'svc nel fold\n",
    "    fold_accuracy = accuracy_score(fold_y_test, fold_y_pred)\n",
    "    \n",
    "    #calcolo l'accuratezza nel fold anche di un dummy classifier con strategia most_frequent, per avere una baseline con cui confrontare l'accuratezza dell'svc\n",
    "    dummy_clf = DummyClassifier(strategy=\"most_frequent\")   # dummy classifier viene utilizzato per avere una baseline\n",
    "    dummy_clf.fit(fold_X_train, fold_y_train)\n",
    "    dummy_score = dummy_clf.score(fold_X_test, fold_y_test)\n",
    "    \n",
    "    #aggiungo le etichette vere e le etichette predette alle liste create inizialmente, per poter calcolare poi le metriche\n",
    "    all_y_true += fold_y_test.tolist()\n",
    "    all_y_pred += fold_y_pred.tolist()\n",
    "    \n",
    "    #stampo l'accuracy e la confronto con la baseline (l'accuracy del dummy classifier)\n",
    "    print(f\"Accuracy fold {i+1}: {fold_accuracy}, baseline: {dummy_score}\")\n",
    "    \n",
    "print(classification_report(all_y_true, all_y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c290fc",
   "metadata": {},
   "source": [
    "Delle 4 rappresentazioni prese in considerazione, quella basata su bigrammi di caratteri ha portato a prestazioni migliori. La proviamo dunque sui test set ufficiali del task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a51c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory dei due test set\n",
    "conllu_dir_test_1 = 'profiling_output_test_1/11936/'\n",
    "conllu_dir_test_2 = 'profiling_output_test_2/11937/'\n",
    "\n",
    "#estraggo i test set e li metto in due liste\n",
    "\n",
    "all_documents_test_1 = [] #inizializza la lista dei documenti, per ora vuota\n",
    "all_documents_test_2 = [] #inizializza la lista dei documenti, per ora vuota\n",
    "\n",
    "#riempio la prima lista\n",
    "for file_name in os.listdir(conllu_dir_test_1): #itera i file nella cartella\n",
    "    file_path = os.path.join(conllu_dir_test_1, file_name)\n",
    "    #per ogni file, crea un oggetto Document\n",
    "    document = Document(file_path)\n",
    "    #utilizza la funzione load_document_sentences per caricare il documento leggendone frasi e token\n",
    "    load_document_sentences(document)\n",
    "    #aggiunge il documento alla lista dei documenti\n",
    "    all_documents_test_1.append(document)\n",
    "    \n",
    "#riempio la seconda lista\n",
    "for file_name in os.listdir(conllu_dir_test_2): #itera i file nella cartella\n",
    "    file_path = os.path.join(conllu_dir_test_2, file_name)\n",
    "    #per ogni file, crea un oggetto Document\n",
    "    document = Document(file_path)\n",
    "    #utilizza la funzione load_document_sentences per caricare il documento leggendone frasi e token\n",
    "    load_document_sentences(document)\n",
    "    #aggiunge il documento alla lista dei documenti\n",
    "    all_documents_test_2.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5c76bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(dual=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearSVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.LinearSVC.html\">?<span>Documentation for LinearSVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC(dual=False)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(dual=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#addestro un svc lineare sul mio sistema migliore in modo da poterlo testare sui test set ufficiali\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "extract_documents_ngrams_normalized(all_documents, \"char\", 2)\n",
    "features = [document.features for document in all_documents]\n",
    "labels = [document.hs for document in all_documents]\n",
    "#inizializzo il vettorizzatore\n",
    "vectorizer = DictVectorizer()\n",
    "\n",
    "#trasformo le features in matrici\n",
    "X = vectorizer.fit_transform(features) #fitta il minmaxscaler e applica subito la trasformazione\n",
    "y = np.array(labels)\n",
    "\n",
    "#modello svc lineare\n",
    "svc_model = LinearSVC(dual=False)\n",
    "#addestro il modello\n",
    "svc_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51595562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#estraggo le features dai documenti di test\n",
    "extract_documents_ngrams_normalized(all_documents_test_1, \"char\", 2)\n",
    "extract_documents_ngrams_normalized(all_documents_test_2, \"char\", 2)\n",
    "\n",
    "#converto le features in una lista di dizionari, per entrambi i documenti di test\n",
    "features_test_1 = [document.features for document in all_documents_test_1]\n",
    "labels_test_1 = [document.hs for document in all_documents_test_1]\n",
    "features_test_2 = [document.features for document in all_documents_test_2]\n",
    "labels_test_2 = [document.hs for document in all_documents_test_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "062c239b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero features test set 1: 737\n",
      "Numero features test set 2: 1938\n"
     ]
    }
   ],
   "source": [
    "#non filtro le features del test set\n",
    "\n",
    "print(f'Numero features test set 1: {get_num_features(features_test_1)}')\n",
    "print(f'Numero features test set 2: {get_num_features(features_test_2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eda6d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converte in matrici numeriche; uso solo transform e non fit_transform perché così il vettorizzatore rimane fittato sui dati di training\n",
    "X_test_1 = vectorizer.transform(features_test_1) \n",
    "X_test_2 = vectorizer.transform(features_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3a5db79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.83      0.75       319\n",
      "           1       0.53      0.33      0.41       181\n",
      "\n",
      "    accuracy                           0.65       500\n",
      "   macro avg       0.61      0.58      0.58       500\n",
      "weighted avg       0.63      0.65      0.63       500\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.88      0.68       641\n",
      "           1       0.68      0.27      0.39       622\n",
      "\n",
      "    accuracy                           0.58      1263\n",
      "   macro avg       0.62      0.57      0.53      1263\n",
      "weighted avg       0.62      0.58      0.53      1263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predizione sul test1\n",
    "y_pred_test_1 = svc_model.predict(X_test_1)\n",
    "print(classification_report(labels_test_1, y_pred_test_1))\n",
    "\n",
    "#predizione sul test2\n",
    "y_pred_test_2 = svc_model.predict(X_test_2)\n",
    "print(classification_report(labels_test_2, y_pred_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991ae593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
